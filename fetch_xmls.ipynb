{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "フォルダ「Ss046」が必要. 中身は空でよい. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーのため422行目「print \"Found %i results\" % count」を「print(\"Found %i results\" % count)」に変更. 428, 435行目も同様. python2と3での違いのため"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーのため429行目「retmode=\"xml\"」を「retmode=\"text\"」に変更. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "424行目「tmp_xml = THEME+'_xml'」を「tmp_xml = THEME+'.xml'」に変更. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーのため486行目「os.path.join(XML_DIR,item)」を「os.path.join(WS_DIR,item)」に変更. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEARCH_WORD = '\"gout\" or\"gouty\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "THEME = 'DID034'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WS_DIR = '/Users/petadimensionlab/ws/refdb/bacteria'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import re, os, sys, glob, operator, shutil, tarfile, sqlite3\n",
    "from datetime import datetime \n",
    "from dateutil import parser\n",
    "from xml.etree.ElementTree import ElementTree, parse\n",
    "from Bio import Entrez\n",
    "Entrez.email = 'petadimension@yahoo.co.jp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/petadimensionlab/ws/refdb/bacteri'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-56761b2fd19b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTHEME_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mndir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTHEME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/petadimensionlab/ws/refdb/bacteri'"
     ]
    }
   ],
   "source": [
    "THEME_DIR = os.path.join(WS_DIR,THEME)\n",
    "if not os.path.isdir(THEME_DIR):\n",
    "    ndir = os.getcwd()\n",
    "    os.chdir(WS_DIR)\n",
    "    os.mkdir(THEME)\n",
    "    os.chdir(ndir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "now = datetime.today()\n",
    "present_time = now.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pubmed:\n",
    "    def __init__(self,THEME):\n",
    "        self.header = THEME\n",
    "        self.db_name = self.header+'Ref.db'\n",
    "        self.type_lst = ['abstract', 'author', 'journal', 'journal-full', 'MeSH', 'pub-type', 'ref', 'title', 'url', 'year']\n",
    "        self.freq_lst = ['author', 'journal', 'MeSH', 'year']\n",
    "        self.date = present_time\n",
    "        #print 'Data collection available for ', ' '.join(self.type_lst)\n",
    "        #print 'Calculation of frequency available for ', ' '.join(self.freq_lst)\n",
    "    def reset_dir(self):\n",
    "        if not os.path.isdir(os.path.join(os.path.join(WS_DIR, self.header),'stat')):\n",
    "            ndir = os.getcwd()\n",
    "            os.chdir(os.path.join(WS_DIR, self.header))\n",
    "            os.mkdir('stat')\n",
    "            os.chdir(ndir)\n",
    "        STAT_DATA_DIR = os.path.join(os.path.join(WS_DIR, self.header),'stat')\n",
    "        XML_DIR = os.path.join(os.path.join(WS_DIR, self.header),'pubmed_xml')\n",
    "        return STAT_DATA_DIR, XML_DIR\n",
    "    def first_fetch(self,query='Psoriasis vulgaris'):\n",
    "        #if not os.path.isdir(XML_DIR):\n",
    "        #    os.mkdir(XML_DIR)\n",
    "        os.chdir(THEME_DIR)\n",
    "        #STAT_DATA_DIR, XML_DIR = self.reset_dir()\n",
    "        search_results = Entrez.read(Entrez.esearch(db=\"pubmed\", term=query, retmax=100000, usehistory=\"y\"))\n",
    "        count = int(search_results[\"Count\"])\n",
    "        if count>100000:\n",
    "            search_results = Entrez.read(Entrez.esearch(db=\"pubmed\", term=query, retmax=count, usehistory=\"y\"))\n",
    "            count = int(search_results[\"Count\"])\n",
    "        print(\"Found %i results\" % count)\n",
    "        batch_size = 200\n",
    "        tmp_xml = THEME+'.xml'\n",
    "        out_handle = open(tmp_xml, 'w')\n",
    "        for start in range(0, count, batch_size):\n",
    "            end = min(count, start+batch_size)\n",
    "            print(\"In Processing... %i to %i\" % (start+1, end))\n",
    "            fetch_handle = Entrez.efetch(db=\"pubmed\", rettype=\"medline\", retmode=\"xml\", retstart=start, retmax=batch_size, webenv=search_results[\"WebEnv\"], query_key=search_results[\"QueryKey\"])\n",
    "            data = fetch_handle.read() ##, encoding='utf-8'##\n",
    "            fetch_handle.close()\n",
    "            try:\n",
    "                out_handle.write(data)\n",
    "            except:\n",
    "                print('%d :Failed in Writing PubMed information in a xml-file.' % start)\n",
    "        out_handle.close()\n",
    "        ## separate a single XML file ##\n",
    "        REPstart = re.compile('<PubmedArticle>')\n",
    "        REPend = re.compile('</PubmedArticle>')\n",
    "        REPpmid = re.compile('\\d{2,}')\n",
    "        fr = open(tmp_xml).readlines()\n",
    "        start_lst = []\n",
    "        end_lst = []\n",
    "        total = len(fr)\n",
    "        for i in range(0,total):\n",
    "            line = fr[i]\n",
    "            if REPstart.match(line):\n",
    "                start_lst.append(str(i))\n",
    "            elif REPend.match(line):\n",
    "                end_lst.append(str(i))\n",
    "        pmid_lst = []\n",
    "        pmid_err = []\n",
    "        for loc in start_lst:\n",
    "            line = fr[int(loc)+2]\n",
    "            res = REPpmid.search(line)\n",
    "            if res=='None':\n",
    "                pmid_err.append(loc)\n",
    "            else:\n",
    "                pmid = res.group(0)\n",
    "                pmid_lst.append(str(pmid))\n",
    "        doc_num = len(pmid_lst)\n",
    "        for i in range(0,doc_num):\n",
    "            save_file = pmid_lst[i]+'.xml'\n",
    "            fw = open(save_file, 'w')\n",
    "            fw.write(fr[0])\n",
    "            fw.write(fr[1])\n",
    "            fw.write(fr[2])\n",
    "            for j in range(int(start_lst[i]), int(end_lst[i])+1):\n",
    "                fw.write(fr[j])\n",
    "            fw.write('</PubmedArticleSet>')\n",
    "            fw.close()\n",
    "        err_file = THEME+'_'+'err'+present_time+'.txt'\n",
    "        fw = open(err_file,'w')\n",
    "        for item in pmid_err:\n",
    "            fw.write(str(item)+'\\n')\n",
    "        fw.close()\n",
    "        os.remove(os.path.join(THEME_DIR,tmp_xml)) # remove non-separated xml file\n",
    "        ## list of separated xml files ##\n",
    "        sep_xml = glob.glob('*.xml')\n",
    "        pmid_list_file = THEME+'_'+'PMID_'+present_time+'.txt'\n",
    "        fw = open(pmid_list_file, 'w')\n",
    "        for item in sep_xml:\n",
    "            ID, ext = item.split('.')\n",
    "            fw.write(ID+'\\n')\n",
    "        fw.close()\n",
    "        os.chdir(WS_DIR)\n",
    "        cmd = 'tar -cjf %s %s' % (THEME+'_'+present_time+'.tar.bz2',THEME+'/')\n",
    "        os.system(cmd)\n",
    "        ## delete files ##\n",
    "        cmd = 'rm -rf %s' % (THEME_DIR)\n",
    "        os.system(cmd)\n",
    "        msg = 'Collection completed: %s' % (THEME)\n",
    "        print(msg)\n",
    "        #os.chdir(THEME_DIR)\n",
    "        #for item in sep_xml:\n",
    "        #    os.remove(item)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16522 results\n",
      "In Processing... 1 to 200\n",
      "In Processing... 201 to 400\n",
      "In Processing... 401 to 600\n",
      "In Processing... 601 to 800\n",
      "In Processing... 801 to 1000\n",
      "In Processing... 1001 to 1200\n",
      "In Processing... 1201 to 1400\n",
      "In Processing... 1401 to 1600\n",
      "In Processing... 1601 to 1800\n",
      "In Processing... 1801 to 2000\n",
      "In Processing... 2001 to 2200\n",
      "In Processing... 2201 to 2400\n",
      "In Processing... 2401 to 2600\n",
      "In Processing... 2601 to 2800\n",
      "In Processing... 2801 to 3000\n",
      "In Processing... 3001 to 3200\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    pm = Pubmed(THEME)\n",
    "    pm.first_fetch(SEARCH_WORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
